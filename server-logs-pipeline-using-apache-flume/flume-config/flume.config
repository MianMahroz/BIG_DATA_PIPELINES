
source_agent.sources = apache_server
source_agent.sinks = HadoopOut

source_agent.sources.apache_server.type = spooldir
source_agent.sources.apache_server.channels = memoryChannel
source_agent.sources.apache_server.spoolDir = /home/hadoop/debuglogs
source_agent.sources.apache_server.fileHeader = true
source_agent.sources.apache_server.interceptors = itime ihost itype



# http://flume.apache.org/FlumeUserGuide.html#timestamp-interceptor
source_agent.sources.apache_server.interceptors.itime.type = timestamp

# http://flume.apache.org/FlumeUserGuide.html#host-interceptor
source_agent.sources.apache_server.interceptors.ihost.type = host
#source_agent.sources.apache_server.interceptors.ihost.useIP = false
source_agent.sources.apache_server.interceptors.ihost.hostHeader = host

# http://flume.apache.org/FlumeUserGuide.html#static-interceptor
source_agent.sources.apache_server.interceptors.itype.type = static
#source_agent.sources.apache_server.interceptors.itype.key = log_type
#source_agent.sources.apache_server.interceptors.itype.value = apache_access_combined

# http://flume.apache.org/FlumeUserGuide.html#memory-channel
source_agent.channels = memoryChannel
source_agent.channels.memoryChannel.type = memory
source_agent.channels.memoryChannel.capacity = 20000
source_agent.channels.memoryChannel.transactionCapacity  = 1000

source_agent.sinks.HadoopOut.type = hdfs
source_agent.sinks.HadoopOut.channel = memoryChannel
source_agent.sinks.HadoopOut.hdfs.path = hdfs://ec2-18-224-252-149.us-east-2.compute.amazonaws.com:8020/user/Mianm/flumelogs

source_agent.sinks.HadoopOut.hdfs.fileType = DataStream
source_agent.sinks.HadoopOut.hdfs.writeFormat = Text
source_agent.sinks.HadoopOut.hdfs.rollSize = 0
source_agent.sinks.HadoopOut.hdfs.rollCount = 10000 
source_agent.sinks.HadoopOut.hdfs.batchSize = 1000